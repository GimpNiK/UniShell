import sys
import os
import tempfile
import shutil
from pathlib import Path

import pytest

sys.path.insert(0, str(Path(__file__).parent.parent))

from unishell import Archive
from unishell import File
from unishell import Dir
from unishell._internal import file_utils as fu
from unishell._internal.encoding_utils import detect_encoding, determine_minimal_encoding


def test_full_workflow_with_encoding_detection(tmp_path: Path):
    """–ü–æ–ª–Ω—ã–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏"""
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏
    files_content = {
        "ascii.txt": "ASCII content",
        "cyrillic.txt": "–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º",
        "japanese.txt": "Êó•Êú¨Ë™û„ÅÆÂÜÖÂÆπ",
        "emoji.txt": "–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å —ç–º–æ–¥–∑–∏ üòä",
    }
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã
    for name, content in files_content.items():
        file_path = tmp_path / name
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É
        encoding = determine_minimal_encoding(content)
        file_path.write_text(content, encoding=encoding)
    
    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
    arc_path = tmp_path / "encoding_test.zip"
    arc = Archive(arc_path, "zip")
    
    for name in files_content:
        arc.add(tmp_path / name)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä—Ö–∏–≤
    extract_dir = tmp_path / "extract_encoding"
    extract_dir.mkdir(exist_ok=True)
    arc.extract(path=extract_dir)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    for name, original_content in files_content.items():
        extracted_file = extract_dir / name
        assert extracted_file.exists()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        detected_encoding = detect_encoding(extracted_file)
        extracted_content = extracted_file.read_text(encoding=detected_encoding)
        
        assert extracted_content == original_content


def test_file_alchemy_objects_integration(tmp_path: Path):
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ FileAlchemy"""
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –ø–æ–º–æ—â—å—é FileAlchemy –æ–±—ä–µ–∫—Ç–æ–≤
    root_dir = Dir(tmp_path / "project")
    root_dir.create()
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ File –æ–±—ä–µ–∫—Ç—ã
    main_file = File(root_dir.path / "main.py")
    main_file.content = "print('Hello, FileAlchemy!')"
    
    config_file = File(root_dir.path / "config.json")
    config_file.content = '{"encoding": "utf-8", "version": "1.0"}'
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫—É
    src_dir = Dir(root_dir.path / "src")
    src_dir.create()
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –≤ –ø–æ–¥–ø–∞–ø–∫–µ
    module_file = File(src_dir.path / "module.py")
    module_file.content = "def hello():\n    return 'Hello from module'"
    
    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    arc_path = tmp_path / "project.zip"
    arc = Archive(arc_path, "zip")
    arc.add(root_dir.path)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤ –Ω–æ–≤–æ–µ –º–µ—Å—Ç–æ
    extract_dir = tmp_path / "extracted_project"
    extract_dir.mkdir(exist_ok=True)
    arc.extract(path=extract_dir)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    assert (extract_dir / "project" / "main.py").exists()
    assert (extract_dir / "project" / "config.json").exists()
    assert (extract_dir / "project" / "src" / "module.py").exists()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
    main_content = (extract_dir / "project" / "main.py").read_text(encoding="utf-8")
    assert "Hello, FileAlchemy!" in main_content


def test_file_utils_integration(tmp_path: Path):
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å file_utils"""
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –ø–æ–º–æ—â—å—é file_utils
    project_dir = tmp_path / "utils_project"
    fu.mkdir(project_dir, parents=True)
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã
    fu.mkfile(project_dir / "readme.txt")
    (project_dir / "readme.txt").write_text("Project documentation", encoding="utf-8")
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫–∏
    fu.mkdir(project_dir / "docs")
    fu.mkdir(project_dir / "src")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö
    (project_dir / "docs" / "guide.txt").write_text("User guide", encoding="utf-8")
    (project_dir / "src" / "main.py").write_text("Main code", encoding="utf-8")
    
    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
    arc_path = tmp_path / "utils_project.zip"
    arc = Archive(arc_path, "zip")
    arc.add(project_dir)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º
    extract_dir = tmp_path / "extracted_utils"
    extract_dir.mkdir(exist_ok=True)
    arc.extract(path=extract_dir)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    assert (extract_dir / "utils_project" / "readme.txt").exists()
    assert (extract_dir / "utils_project" / "docs" / "guide.txt").exists()
    assert (extract_dir / "utils_project" / "src" / "main.py").exists()


def test_mixed_archive_formats_workflow(tmp_path: Path):
    """–†–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å —Å —Ä–∞–∑–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ –∞—Ä—Ö–∏–≤–æ–≤"""
    # –°–æ–∑–¥–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    data_dir = tmp_path / "data"
    data_dir.mkdir()
    
    files = {
        "text.txt": "Text content",
        "data.json": '{"key": "value"}',
        "script.py": "print('Hello')",
    }
    
    for name, content in files.items():
        (data_dir / name).write_text(content, encoding="utf-8")
    
    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤—ã —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
    formats = ["zip", "7z", "tar", "tar.gz", "tar.bz2"]
    archives = {}
    
    for fmt in formats:
        arc_path = tmp_path / f"data.{fmt}"
        arc = Archive(arc_path, fmt)
        arc.add(data_dir)
        archives[fmt] = arc
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –∞—Ä—Ö–∏–≤—ã
    for fmt, arc in archives.items():
        extract_dir = tmp_path / f"extract_{fmt}"
        extract_dir.mkdir(exist_ok=True)
        arc.extract(path=extract_dir)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
        for name, content in files.items():
            extracted_file = extract_dir / "data" / name
            assert extracted_file.exists()
            assert extracted_file.read_text(encoding="utf-8") == content


def test_password_protected_workflow(tmp_path: Path):
    """–†–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å —Å –∑–∞—â–∏—â–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–æ–ª–µ–º –∞—Ä—Ö–∏–≤–∞–º–∏"""
    password = "secure-password-123"
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    secret_dir = tmp_path / "secrets"
    secret_dir.mkdir()
    
    secret_files = {
        "credentials.txt": "username: admin\npassword: secret123",
        "config.ini": "[database]\nhost=localhost\nport=5432",
        "private.key": "-----BEGIN PRIVATE KEY-----\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQC...",
    }
    
    for name, content in secret_files.items():
        (secret_dir / name).write_text(content, encoding="utf-8")
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞—â–∏—â–µ–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤
    protected_arc_path = tmp_path / "secrets.zip"
    protected_arc = Archive(protected_arc_path, "zip", password=password)
    protected_arc.add(secret_dir)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–∞—Ä–æ–ª–µ–º
    extract_dir = tmp_path / "extract_secrets"
    extract_dir.mkdir(exist_ok=True)
    
    # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –∞—Ä—Ö–∏–≤–∞ —Å –ø–∞—Ä–æ–ª–µ–º
    extract_arc = Archive(protected_arc_path, password=password)
    extract_arc.extract(path=extract_dir)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
    for name, content in secret_files.items():
        extracted_file = extract_dir / "secrets" / name
        assert extracted_file.exists()
        assert extracted_file.read_text(encoding="utf-8") == content


def test_large_project_structure(tmp_path: Path):
    """–¢–µ—Å—Ç —Å –±–æ–ª—å—à–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –ø—Ä–æ–µ–∫—Ç–∞"""
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–æ–ª—å—à–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    project_structure = {
        "README.md": "# Project\nThis is a test project",
        "requirements.txt": "pytest\nrequests\nnumpy",
        "setup.py": "from setuptools import setup\nsetup(name='test')",
        "src/": None,  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        "src/main.py": "def main():\n    print('Hello')",
        "src/utils.py": "def helper():\n    return True",
        "tests/": None,  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        "tests/test_main.py": "def test_main():\n    assert True",
        "docs/": None,  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        "docs/guide.md": "# Guide\nUser guide here",
        "data/": None,  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        "data/sample.json": '{"test": "data"}',
    }
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    for path_str, content in project_structure.items():
        full_path = tmp_path / "large_project" / path_str
        
        if content is None:  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
            full_path.mkdir(parents=True, exist_ok=True)
        else:  # –§–∞–π–ª
            full_path.parent.mkdir(parents=True, exist_ok=True)
            full_path.write_text(content, encoding="utf-8")
    
    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
    arc_path = tmp_path / "large_project.zip"
    arc = Archive(arc_path, "zip")
    arc.add(tmp_path / "large_project")
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º
    extract_dir = tmp_path / "extracted_large"
    extract_dir.mkdir(exist_ok=True)
    arc.extract(path=extract_dir)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    for path_str, content in project_structure.items():
        if content is not None:  # –§–∞–π–ª
            extracted_file = extract_dir / "large_project" / path_str
            assert extracted_file.exists()
            assert extracted_file.read_text(encoding="utf-8") == content


def test_error_recovery_workflow(tmp_path: Path):
    """–†–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º –ø–æ—Å–ª–µ –æ—à–∏–±–æ–∫"""
    # –°–æ–∑–¥–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    valid_dir = tmp_path / "valid_data"
    valid_dir.mkdir()
    (valid_dir / "file1.txt").write_text("Valid content 1", encoding="utf-8")
    (valid_dir / "file2.txt").write_text("Valid content 2", encoding="utf-8")
    
    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
    arc_path = tmp_path / "recovery_test.zip"
    arc = Archive(arc_path, "zip")
    arc.add(valid_dir)
    
    # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
    extract_dir = tmp_path / "extract_recovery"
    extract_dir.mkdir(exist_ok=True)
    
    with pytest.raises(ValueError):
        arc.extract(member="nonexistent.txt", path=extract_dir)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    arc.extract(path=extract_dir)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
    assert (extract_dir / "valid_data" / "file1.txt").exists()
    assert (extract_dir / "valid_data" / "file2.txt").exists()


def test_cross_platform_compatibility(tmp_path: Path):
    """–¢–µ—Å—Ç –∫—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã —Å –∏–º–µ–Ω–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–æ–±–ª–µ–º–Ω—ã–º–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –û–°
    problematic_names = [
        "file with spaces.txt",
        "file-with-dashes.txt",
        "file_with_underscores.txt",
        "—Ñ–∞–π–ª_–Ω–∞_—Ä—É—Å—Å–∫–æ–º.txt",
        "„Éï„Ç°„Ç§„É´.txt",
    ]
    
    for name in problematic_names:
        file_path = tmp_path / name
        file_path.write_text(f"Content for {name}", encoding="utf-8")
    
    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
    arc_path = tmp_path / "cross_platform.zip"
    arc = Archive(arc_path, "zip")
    
    for name in problematic_names:
        arc.add(tmp_path / name)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º
    extract_dir = tmp_path / "extract_cross_platform"
    extract_dir.mkdir(exist_ok=True)
    arc.extract(path=extract_dir)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ (–∏–º–µ–Ω–∞ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã)
    archive_files = arc.list_files()
    assert len(archive_files) == len(problematic_names)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑–≤–ª–µ—á–µ–Ω—ã
    extracted_files = list(extract_dir.iterdir())
    assert len(extracted_files) == len(problematic_names)


def test_memory_efficient_processing(tmp_path: Path):
    """–¢–µ—Å—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–º—è—Ç–∏"""
    # –°–æ–∑–¥–∞–µ–º –º–Ω–æ–≥–æ –º–∞–ª–µ–Ω—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
    num_files = 100
    files = []
    
    for i in range(num_files):
        file_path = tmp_path / f"small_file_{i:03d}.txt"
        file_path.write_text(f"Content {i}", encoding="utf-8")
        files.append(file_path)
    
    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
    arc_path = tmp_path / "memory_efficient.zip"
    arc = Archive(arc_path, "zip")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª—ã –ø–æ –æ–¥–Ω–æ–º—É (–∏–º–∏—Ç–∞—Ü–∏—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)
    for file_path in files:
        arc.add(file_path)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º
    extract_dir = tmp_path / "extract_memory_efficient"
    extract_dir.mkdir(exist_ok=True)
    arc.extract(path=extract_dir)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
    for i in range(num_files):
        assert (extract_dir / f"small_file_{i:03d}.txt").exists()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∞—Ä—Ö–∏–≤ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ —Ñ–∞–π–ª—ã
    assert len(arc.list_files()) == num_files


def test_complex_nested_structure(tmp_path: Path):
    """–¢–µ—Å—Ç —Å–ª–æ–∂–Ω–æ–π –≤–ª–æ–∂–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
    # –°–æ–∑–¥–∞–µ–º –≥–ª—É–±–æ–∫–æ –≤–ª–æ–∂–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    deep_structure = {
        "level1/": None,
        "level1/level2/": None,
        "level1/level2/level3/": None,
        "level1/level2/level3/level4/": None,
        "level1/level2/level3/level4/deep_file.txt": "Deep content",
        "level1/level2/mid_file.txt": "Mid content",
        "level1/top_file.txt": "Top content",
        "parallel/": None,
        "parallel/other_file.txt": "Parallel content",
    }
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    for path_str, content in deep_structure.items():
        full_path = tmp_path / "complex" / path_str
        
        if content is None:  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
            full_path.mkdir(parents=True, exist_ok=True)
        else:  # –§–∞–π–ª
            full_path.parent.mkdir(parents=True, exist_ok=True)
            full_path.write_text(content, encoding="utf-8")
    
    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
    arc_path = tmp_path / "complex_structure.zip"
    arc = Archive(arc_path, "zip")
    arc.add(tmp_path / "complex")
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º
    extract_dir = tmp_path / "extract_complex"
    extract_dir.mkdir(exist_ok=True)
    arc.extract(path=extract_dir)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    for path_str, content in deep_structure.items():
        if content is not None:  # –§–∞–π–ª
            extracted_file = extract_dir / "complex" / path_str
            assert extracted_file.exists()
            assert extracted_file.read_text(encoding="utf-8") == content
